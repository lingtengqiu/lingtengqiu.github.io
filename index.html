<!DOCTYPE HTML>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="author" content="Lingteng Qiu">
  <meta name="description" content="Lingteng Qiu's Homepage"
  <meta name="keywords" content="Lingteng Qiu,邱陵腾,homepage,主页, PhD, computer vision, CUHK-SZ, 3D reconstruction, Pose estimation, Neural rendering, Digital Garment>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Jingxiang Sun (邱陵腾)'s Homepage</title>
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>lingtengqiu (邱陵腾)</name>
              </p>
              <p style="text-align:center">
                <a href="mailto:qiulingteng@link.cuhk.edu.cn">Email</a>
                &nbsp; &nbsp;&nbsp;&nbsp; <a href="https://scholar.google.com/citations?user=YJFpZ2kAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a> &nbsp; &nbsp;&nbsp;&nbsp;<a href="https://github.com/lingtengqiu">Github</a>
              </p>

              <div class="w3-content" style="text-align: justify">
              <p>I am an PhD student of <a href="https://sse.cuhk.edu.cn/">School of Science adn Engineering, The Chinese University of Hongkong, Shenzhen</a> in fall, 2020 and under the supervision of <a href="https://mypage.cuhk.edu.cn/academics/hanxiaoguang/">Prof. Xiaoguang Han</a>. 
                Prior to CUHK-Shenzhen I obtained M.S. from <a href="http://www.hit.edu.cn/">Department of Automation, Harbin Institue of Technology</a> and B.S. from <a href="https://www.fzu.edu.cn/">Fuzhou University</a>. 
                <br>
                <br>
                My research interests are in computer vision and machine learning. Specifically, learning based methods 
                for 3D vision, human pose estimation, neural rendring, etc.
              </p>
              </div>
            </td>
            <td style="padding:15% 7% 7% 7%;width:40%;max-width:40%">
              <a href="images/Lingtengqiu.jpg"><img style="width:100%;max-width:120%" alt="profile photo" src="images/Lingtengqiu.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              2022-03: 	Two papers are accepted by CVPR 2022, more details coming soon!<br>
              2021-03: 	One papers is accepted by CVPR 2021!<br>
              2020-07: 	One papers is accepted by ECCV 2020! Code and dataset are <a href="https://github.com/lingtengqiu/OPEC-Net">available</a>.
            </p>
          </td>
        </tr>
      </tbody></table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr></tr>
            <td style="padding:10px;width:25%;vertical-align:middle">
                <div class="one" >
                    <img src='./2022/ETHSeg/img_comparison.jpg' style="height:100%;width:140%; position: absolute;top: -0%">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>ETHSeg: An Amodel Instance Segmentation Network and a Real-world Dataset for X-Ray Waste Inspection</papertitle>
                <br>
                <strong>Lingteng Qiu</strong>, Zhangyang Xiong, Xuhao Wang, KenKun Liu, <a href="https://guanyingc.github.io/">Guanying Chen</a>, <a href="https://mypage.cuhk.edu.cn/academics/hanxiaoguang/">Xiaoguang Han</a>, Shuguang Cui
                <br>
                <em>2022 IEEE Conference on Computer Vision and Pattern Recognition</em>, CVPR 2022, 
                <br>
                <a href="./2022/ETHSeg/">[Project]</a>
                <a href="">[PDF]</a>
                <a href="">[Dataset]</a>
				<a href="images/fenerf.txt">[BibTeX]</a>
                <br>
                <p>we propose FENeRF, a 3D-aware generator that can produce view-consistent and locally-editable portrait images. Our method uses two decoupled latent codes to generate corresponding facial semantics and texture in a spatial aligned 3D volume with shared geometry. We also reveal that joint learning semantics and texture helps to generate finer geometry.</p>
            </td>
        </tr>

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
		<video playsinline autoplay loop preload muted style="width:100%;max-width:100%; position: absolute;top: -5%">
                <source src='images/ijcv22_imocap.mp4'>
		</video>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>iMoCap: Motion Capture from Internet Videos</papertitle>
                <br>
                Junting Dong*, Qing Shuai*, <strong>Jingxiang Sun</strong>, Yuanqing Zhang, Hujun Bao, Xiaowei Zhou (* equal contribution)
                <br>
                <em>2022 International Journal of Computer Vision </em>, IJCV 2022, 
                <br>
                <a href="https://link.springer.com/article/10.1007/s11263-022-01596-7">[PDF]</a>
				<a href="images/imocap.txt">[BibTeX]</a>
                <br>
                <p>We propose a novel optimization-based framework and experimentally demonstrate its ability to recover much more precise and detailed motion from multiple videos, compared against monocular pose estimation methods.</p>
            </td>
        </tr>

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                    <img src='images/icbda_bus.png' style="width:100%;max-width:100%; position: absolute;top: -5%">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>BusTime: Which is the Right Prediction Model for My Bus Arrival Time?</papertitle>
                <br>
                Dairui Liu, <strong>Jingxiang Sun</strong>, Shen Wang
                <br>
                <em>2020 IEEE International Conference on Big Data Analytics</em>, ICBDA 2020, 
                <br>
                <a href="https://arxiv.org/pdf/2003.10373.pdf">[PDF]</a>
				        <a href="images/bus.txt">[BibTeX]</a>
                <br>
                <p>We proposed a general and practical evaluation framework for analysing various widely used prediction models (i.e. delay, k- nearest-neighbor, kernel regression, additive model, and recur- rent neural network using long short term memory) for bus arrival time.</p>
            </td>
        </tr>

        <tr></tr>
            <td style="padding:20px;width:0%;vertical-align:middle">
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
		<hr style="margin-top:0px">
                <p>The website template was adapted from <a href="https://yudeng.github.io/">Yu Deng</a>.</p>
            </td>
        </tr>

      </td>
    </tr>
  </table>
</body>

</html>
